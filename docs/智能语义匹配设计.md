# 智能语义匹配设计文档

## 一、问题背景

在自动化测试中，OCR识别可能存在错误，例如：
- 用例中要求匹配："捕获屏幕"
- OCR识别结果："埔获屏幕" 或 "埔获屏幕"

传统的字符串匹配无法处理这种情况，导致测试失败。

## 二、解决方案：智能语义匹配

### 2.1 核心思想

**大模型在自动化测试中扮演关键角色**：
- 即使OCR识别不准确，大模型也能理解语义相关性
- 能够将"捕获屏幕"和"埔获屏幕"自动关联起来
- 提供智能匹配，提升测试成功率

### 2.2 架构设计

```
┌─────────────────────────────────────────┐
│        智能语义匹配层                    │
├─────────────────────────────────────────┤
│ 第一层：直接匹配（快速、准确）            │
│  - 完全匹配：OCR结果 = 目标文本          │
│  - 包含匹配：OCR结果包含目标文本          │
│  - 响应时间：< 1ms                      │
├─────────────────────────────────────────┤
│ 第二层：语义匹配（智能、容错）            │
│  - 使用大模型理解语义相关性               │
│  - 处理OCR识别错误                       │
│  - 响应时间：2-5秒（本地模型）           │
└─────────────────────────────────────────┘
```

### 2.3 工作流程

```
1. 测试用例要求：点击"捕获屏幕"按钮
   ↓
2. OCR识别结果：["埔获屏幕", "点击中心", "刷新"]
   ↓
3. 直接匹配：失败（"捕获屏幕" ≠ "埔获屏幕"）
   ↓
4. 语义匹配：使用大模型
   - 输入：目标文本="捕获屏幕"，OCR结果=["埔获屏幕", ...]
   - 大模型分析：理解"捕获屏幕"和"埔获屏幕"的语义相关性
   - 输出：匹配成功，置信度=0.85
   ↓
5. 返回匹配结果：成功定位到"埔获屏幕"按钮
```

## 三、实现方案

### 3.1 核心组件

#### SemanticMatcher（语义匹配器）

**功能**：
- 智能文本匹配
- 支持直接匹配和语义匹配
- 自动选择最佳匹配策略

**API**：
```kotlin
suspend fun matchText(
    targetText: String,        // 目标文本（来自测试用例）
    ocrResult: OcrResult?,      // OCR识别结果
    useSemanticMatch: Boolean = true  // 是否启用语义匹配
): MatchResult
```

**匹配结果**：
```kotlin
data class MatchResult(
    val success: Boolean,           // 是否匹配成功
    val matchedBlock: TextBlock?,   // 匹配到的文本块
    val confidence: Float,          // 匹配置信度（0.0-1.0）
    val matchType: MatchType,       // 匹配方式（DIRECT/SEMANTIC）
    val error: String?              // 错误信息
)
```

### 3.2 集成点

#### 1. ElementLocator（元素定位器）

**修改前**：
```kotlin
// 简单的字符串包含匹配
val matchedBlock = ocrResult.textBlocks.find { block ->
    block.text.contains(text, ignoreCase = true)
}
```

**修改后**：
```kotlin
// 使用语义匹配器
val matchResult = SemanticMatcher.matchText(text, ocrResult, useSemanticMatch = true)
if (matchResult.success) {
    // 定位成功，返回坐标
    return LocateResult(success = true, point = Point(...))
}
```

#### 2. TestExecutor（测试执行器）

**验证逻辑**：
```kotlin
// 验证文本存在
private suspend fun verifyTextExists(text: String, ocrResult: OcrResult?): VerificationResult {
    val matchResult = SemanticMatcher.matchText(text, ocrResult, useSemanticMatch = true)
    return if (matchResult.success) {
        VerificationResult(passed = true, message = "文本存在（语义匹配）")
    } else {
        VerificationResult(passed = false, message = "文本不存在")
    }
}
```

## 四、大模型集成方案

### 4.1 当前实现（临时方案）

**使用编辑距离（Levenshtein距离）**：
- 计算文本相似度
- 相似度 > 0.6 认为匹配成功
- 这是一个fallback方案

**示例**：
- "捕获屏幕" vs "埔获屏幕"：相似度 ≈ 0.75 → 匹配成功

### 4.2 未来实现（大模型方案）

#### 方案1：本地LLM（推荐）

**模型选择**：
- Qwen-1.8B（轻量级，8GB内存设备）
- Qwen-7B（完整功能，12GB+内存设备）

**Prompt示例**：
```
你是一个文本匹配专家。请判断以下文本列表中，哪些文本与目标文本语义相似。

目标文本：捕获屏幕
OCR识别结果：["埔获屏幕", "捕获屏幕", "点击中心", "刷新"]

请返回JSON格式的匹配结果，包含每个文本的相似度分数（0.0-1.0）。
```

**实现位置**：
```kotlin
suspend fun semanticMatchWithLLM(
    targetText: String,
    ocrTexts: List<String>
): List<Pair<String, Float>> {
    // TODO: 集成本地LLM（Qwen-1.8B/7B）
    val prompt = buildSemanticMatchPrompt(targetText, ocrTexts)
    val result = llmModel.generate(prompt)
    return parseMatchResult(result)
}
```

#### 方案2：Vision-Language模型（高级）

**模型选择**：
- Qwen-VL（支持图像+文本理解）

**优势**：
- 可以同时理解图像和文本
- 更准确的语义匹配
- 能理解上下文和布局

**实现位置**：
```kotlin
suspend fun semanticMatchWithVisionLanguage(
    targetText: String,
    screenshot: Bitmap,
    ocrResult: OcrResult
): MatchResult {
    // TODO: 集成Qwen-VL
    val prompt = buildVisionLanguagePrompt(targetText, screenshot, ocrResult)
    val result = visionLanguageModel.understand(prompt)
    return parseMatchResult(result)
}
```

#### 方案3：云端API（可选）

**适用场景**：
- 企业级大规模使用
- 需要最新模型能力
- 可以接受网络延迟

**API选择**：
- GPT-4V
- Claude Vision
- 其他Vision-Language API

## 五、智能选择策略

### 5.1 何时使用直接匹配

**条件**：
- OCR结果与目标文本完全匹配
- OCR结果包含目标文本
- 响应时间要求极高（< 1ms）

**优势**：
- 速度快
- 准确率高
- 无需大模型

### 5.2 何时使用语义匹配

**条件**：
- 直接匹配失败
- OCR识别可能存在错误
- 需要理解语义相关性

**优势**：
- 容错能力强
- 能处理OCR错误
- 理解语义相关性

### 5.3 自动选择逻辑

```kotlin
suspend fun matchText(targetText: String, ocrResult: OcrResult?): MatchResult {
    // 第一步：尝试直接匹配（快速）
    val directMatch = tryDirectMatch(targetText, ocrResult)
    if (directMatch.success) {
        return directMatch  // 直接匹配成功，直接返回
    }
    
    // 第二步：直接匹配失败，使用语义匹配
    return trySemanticMatch(targetText, ocrResult)
}
```

## 六、使用示例

### 6.1 元素定位

```kotlin
// 测试用例：点击"捕获屏幕"按钮
val action = Action.Click(
    locateBy = LocateBy.TEXT,
    value = "捕获屏幕"
)

// OCR识别结果：["埔获屏幕", "点击中心", "刷新"]
val ocrResult = ocrRecognizer.recognize(screenshot)

// 使用语义匹配定位
val locateResult = ElementLocator.locateAsync(
    locateBy = LocateBy.TEXT,
    value = "捕获屏幕",
    ocrResult = ocrResult,
    useSemanticMatch = true  // 启用语义匹配
)

// 结果：匹配成功，定位到"埔获屏幕"按钮
if (locateResult.success) {
    DeviceController.click(locateResult.point.x, locateResult.point.y)
}
```

### 6.2 文本验证

```kotlin
// 测试用例：验证屏幕上存在"捕获屏幕"文字
val verification = Verification(
    type = VerificationType.TEXT_EXISTS,
    value = "捕获屏幕"
)

// OCR识别结果：["埔获屏幕", ...]
val ocrResult = ocrRecognizer.recognize(screenshot)

// 使用语义匹配验证
val verifyResult = testExecutor.verify(verification) { ocrResult }

// 结果：验证通过（语义匹配成功）
if (verifyResult.passed) {
    Log.d("Test", "验证通过：${verifyResult.message}")
    // 输出：验证通过：文本 '捕获屏幕' 存在（语义匹配，置信度: 0.85）
}
```

## 七、性能考虑

### 7.1 响应时间

| 匹配方式 | 响应时间 | 适用场景 |
|---------|---------|---------|
| 直接匹配 | < 1ms | 简单场景，OCR准确 |
| 语义匹配（编辑距离） | < 10ms | 临时方案，简单相似度 |
| 语义匹配（本地LLM） | 2-5秒 | 复杂场景，需要语义理解 |
| 语义匹配（云端API） | 1-3秒 | 企业级，需要最新能力 |

### 7.2 优化策略

1. **缓存机制**：缓存常见匹配结果
2. **并行处理**：多个匹配任务并行执行
3. **模型预加载**：提前加载大模型
4. **智能降级**：根据设备性能选择策略

## 八、总结

### 8.1 核心价值

1. **容错能力**：即使OCR识别错误，也能正确匹配
2. **智能理解**：理解语义相关性，而不仅仅是字面匹配
3. **自动选择**：根据场景自动选择最佳匹配策略
4. **大模型核心**：大模型在整个自动化测试中扮演关键角色

### 8.2 实施路线图

**Phase 1（当前）**：
- ✅ 实现语义匹配框架
- ✅ 使用编辑距离作为临时方案
- ✅ 集成到ElementLocator和TestExecutor

**Phase 2（中期）**：
- ⏳ 集成本地LLM（Qwen-1.8B/7B）
- ⏳ 实现真正的语义匹配
- ⏳ 优化性能和准确率

**Phase 3（长期）**：
- ⏳ 集成Vision-Language模型（Qwen-VL）
- ⏳ 支持图像+文本的联合理解
- ⏳ 实现更智能的匹配策略

---

**设计理念**：大模型在自动化测试中扮演关键角色，通过语义理解解决OCR识别错误的问题，提升测试成功率。

