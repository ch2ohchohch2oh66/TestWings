# TestWings 架构设计文档

## 一、整体架构

### 1.1 系统分层架构

```
┌─────────────────────────────────────────────────────────────┐
│                      用户接口层                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  Web管理端   │  │  移动端APP   │  │  CLI命令行   │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└────────────────────┬───────────────────────────────────────┘
                     │
┌────────────────────▼───────────────────────────────────────┐
│                      测试用例管理层                           │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  用例解析    │  │  用例存储    │  │  用例执行    │      │
│  │  (Parser)    │  │  (Database)  │  │  (Executor)  │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└────────────────────┬───────────────────────────────────────┘
                     │
┌────────────────────▼───────────────────────────────────────┐
│                      AI核心引擎层                            │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  用例理解    │  │  屏幕理解    │  │  操作规划    │      │
│  │  (LLM)       │  │  (Vision+OCR)│  │  (LLM)       │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└────────────────────┬───────────────────────────────────────┘
                     │
┌────────────────────▼───────────────────────────────────────┐
│                      设备控制层                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  屏幕捕获    │  │  元素定位    │  │  操作执行    │      │
│  │  (Capture)   │  │  (Locator)   │  │  (Executor)  │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└────────────────────┬───────────────────────────────────────┘
                     │
┌────────────────────▼───────────────────────────────────────┐
│                      结果分析层                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  结果验证    │  │  报告生成    │  │  问题分析    │      │
│  │  (Verifier)  │  │  (Reporter)  │  │  (Analyzer)  │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 核心模块说明

#### 1.2.1 用户接口层
- **Web管理端**：提供测试用例管理、执行监控、报告查看等功能
- **移动端APP**：作为测试执行代理，安装在测试设备上
- **CLI命令行**：提供命令行工具，支持CI/CD集成

#### 1.2.2 测试用例管理层
- **用例解析**：支持多种格式（自然语言、JSON、YAML、Python脚本）
- **用例存储**：用例数据库，支持版本管理
- **用例执行**：测试执行引擎，支持并行执行

#### 1.2.3 AI核心引擎层
- **用例理解**：使用LLM理解测试用例意图
- **屏幕理解**：结合OCR和视觉模型理解屏幕内容
- **操作规划**：生成操作序列和决策逻辑

#### 1.2.4 设备控制层
- **屏幕捕获**：实时获取设备屏幕截图
- **元素定位**：定位UI元素位置
- **操作执行**：执行点击、滑动、输入等操作

#### 1.2.5 结果分析层
- **结果验证**：验证测试步骤执行结果
- **报告生成**：生成测试报告（HTML、JSON、PDF）
- **问题分析**：分析失败原因，提供修复建议

---

## 二、核心流程设计

### 2.1 测试执行主流程

```python
# 伪代码示例
class TestExecutor:
    def execute_test_case(self, test_case):
        # 1. 理解测试用例
        test_plan = self.ai_engine.understand_test_case(test_case)
        
        # 2. 执行测试步骤
        for step in test_plan.steps:
            # 2.1 捕获屏幕
            screenshot = self.device_controller.capture_screen()
            
            # 2.2 理解屏幕内容
            screen_state = self.ai_engine.understand_screen(screenshot)
            
            # 2.3 匹配目标元素
            target_element = self.element_locator.find_element(
                step.target, screen_state
            )
            
            # 2.4 执行操作
            result = self.device_controller.execute_action(
                step.action, target_element, step.params
            )
            
            # 2.5 验证结果
            verification_result = self.result_verifier.verify(
                step.expected, screenshot, result
            )
            
            # 2.6 记录结果
            self.result_recorder.record_step_result(
                step, result, verification_result
            )
            
            # 2.7 处理异常
            if not verification_result.success:
                self.exception_handler.handle(verification_result)
        
        # 3. 生成报告
        report = self.report_generator.generate(test_case, results)
        return report
```

### 2.2 AI理解流程

```python
# 用例理解流程
class TestCaseUnderstanding:
    def understand_test_case(self, test_case):
        # 1. 解析用例格式
        parsed_case = self.parser.parse(test_case)
        
        # 2. 使用LLM理解意图
        prompt = self.build_understanding_prompt(parsed_case)
        understanding = self.llm.generate(prompt)
        
        # 3. 生成测试计划
        test_plan = self.plan_generator.generate(understanding)
        
        return test_plan

# 屏幕理解流程
class ScreenUnderstanding:
    def understand_screen(self, screenshot):
        # 1. OCR识别文字
        text_elements = self.ocr_engine.recognize(screenshot)
        
        # 2. UI元素检测
        ui_elements = self.ui_detector.detect(screenshot)
        
        # 3. Accessibility信息（如果可用）
        accessibility_info = self.accessibility_service.get_info()
        
        # 4. 使用LLM理解屏幕语义
        screen_description = self.build_screen_description(
            text_elements, ui_elements, accessibility_info
        )
        semantic_understanding = self.llm.understand_screen(
            screenshot, screen_description
        )
        
        return ScreenState(
            text_elements=text_elements,
            ui_elements=ui_elements,
            accessibility_info=accessibility_info,
            semantic_understanding=semantic_understanding
        )
```

---

## 三、技术栈选型

### 3.1 移动端（Android/iOS）

#### Android
- **屏幕捕获**：MediaProjection API
- **UI访问**：AccessibilityService / UIAutomator2
- **操作执行**：UIAutomator2 / ADB命令
- **OCR**：PaddleOCR（移动端优化版本）
- **图像处理**：OpenCV for Android

#### iOS
- **屏幕捕获**：ScreenCapture API
- **UI访问**：XCUITest / Accessibility API
- **操作执行**：XCUITest / 私有API（需越狱）
- **OCR**：Vision Framework / PaddleOCR
- **图像处理**：Core Image / OpenCV

### 3.2 AI模型（完全本地部署优先）

#### 大语言模型（LLM）- 本地部署
- **推荐模型**：Qwen-7B-Chat（INT8 量化）、Qwen-1.8B-Chat（INT8 量化）
- **推理框架**：ONNX Runtime、TensorFlow Lite
- **模型大小**：1-5GB（量化后）
- **用途**：用例理解、操作规划、屏幕语义理解（共享同一模型）

#### 视觉模型 - 本地部署
- **OCR**：PaddleOCR Mobile（推荐）、EasyOCR、Tesseract
- **目标检测**：YOLOv8 Nano（UI 元素检测）
- **视觉-语言模型**：Qwen-VL-Chat（INT8 量化，可选）

#### 企业级可选方案
- **云端 LLM**：GPT-4、Claude、Qwen-7B/14B（自建服务）
- **云端视觉理解**：GPT-4V、Claude Vision、Qwen-VL

### 3.3 数据存储（完全本地）

- **数据库**：SQLite（用例存储、执行结果）
- **文件存储**：本地文件系统（截图、日志、报告）
- **缓存**：内存缓存（模型推理结果、UI 元素识别结果）

### 3.4 企业级后端服务（可选）

**仅在企业级混合部署场景需要：**
- **Web框架**：FastAPI / Flask
- **数据库**：PostgreSQL（用例存储）、Redis（缓存）
- **消息队列**：RabbitMQ / Kafka（异步任务）
- **任务调度**：Celery
- **API网关**：Nginx
- **LLM服务**：vLLM、TensorRT-LLM

### 3.5 移动端APP

- **开发框架**：Android 原生（Kotlin/Java）
- **UI框架**：Jetpack Compose 或传统 View 系统
- **数据库**：Room（SQLite 封装）
- **异步处理**：Kotlin Coroutines

---

## 四、数据模型设计

### 4.1 测试用例模型

```python
class TestCase:
    id: str
    name: str
    description: str
    format: str  # 'natural_language', 'json', 'yaml', 'python'
    content: str  # 原始用例内容
    parsed_content: dict  # 解析后的结构化内容
    app_package: str  # 目标应用包名
    created_at: datetime
    updated_at: datetime
    version: int

class TestStep:
    step_id: int
    action: str  # 'click', 'input', 'swipe', 'verify', 'wait'
    target: str  # 目标元素描述
    params: dict  # 操作参数
    expected: dict  # 预期结果
    timeout: int  # 超时时间（秒）
```

### 4.2 屏幕状态模型

```python
class ScreenState:
    screenshot_path: str
    timestamp: datetime
    text_elements: List[TextElement]
    ui_elements: List[UIElement]
    accessibility_tree: dict  # UI层级树
    semantic_description: str  # LLM生成的语义描述

class TextElement:
    text: str
    bbox: BoundingBox  # 边界框
    confidence: float

class UIElement:
    type: str  # 'button', 'input', 'image', 'text'
    bbox: BoundingBox
    attributes: dict  # 属性（颜色、大小等）
    confidence: float
```

### 4.3 执行结果模型

```python
class TestExecution:
    id: str
    test_case_id: str
    device_id: str
    status: str  # 'running', 'passed', 'failed', 'error'
    start_time: datetime
    end_time: datetime
    steps: List[StepExecution]
    screenshots: List[str]
    report_path: str

class StepExecution:
    step_id: int
    action: str
    target: str
    status: str  # 'success', 'failed', 'skipped'
    execution_time: float
    screenshot_before: str
    screenshot_after: str
    error_message: str
    verification_result: VerificationResult
```

---

## 五、关键算法设计

### 5.1 元素定位算法

```python
class ElementLocator:
    def find_element(self, target_description, screen_state):
        """
        多策略元素定位
        """
        # 策略1：语义匹配（优先）
        candidates = self.semantic_match(target_description, screen_state)
        if candidates:
            return self.select_best_candidate(candidates)
        
        # 策略2：文本匹配
        candidates = self.text_match(target_description, screen_state)
        if candidates:
            return self.select_best_candidate(candidates)
        
        # 策略3：视觉匹配
        candidates = self.visual_match(target_description, screen_state)
        if candidates:
            return self.select_best_candidate(candidates)
        
        # 策略4：Accessibility匹配
        candidates = self.accessibility_match(target_description, screen_state)
        if candidates:
            return self.select_best_candidate(candidates)
        
        raise ElementNotFoundError(f"无法找到元素: {target_description}")
    
    def semantic_match(self, target, screen_state):
        """
        使用LLM进行语义匹配
        """
        prompt = f"""
        在以下屏幕元素中，找到最匹配"{target}"的元素：
        {screen_state.semantic_description}
        
        返回匹配的元素ID和匹配度。
        """
        result = self.llm.generate(prompt)
        return self.parse_matching_result(result)
```

### 5.2 异常处理策略

```python
class ExceptionHandler:
    def handle(self, exception, context):
        """
        智能异常处理
        """
        if isinstance(exception, ElementNotFoundError):
            return self.handle_element_not_found(exception, context)
        elif isinstance(exception, TimeoutError):
            return self.handle_timeout(exception, context)
        elif isinstance(exception, VerificationFailedError):
            return self.handle_verification_failed(exception, context)
        else:
            return self.handle_unknown_error(exception, context)
    
    def handle_element_not_found(self, error, context):
        """
        元素未找到的处理策略
        """
        # 策略1：重新识别屏幕
        new_screen_state = self.screen_understanding.understand_screen(
            self.device_controller.capture_screen()
        )
        
        # 策略2：尝试滚动查找
        if self.should_scroll(context):
            self.device_controller.scroll()
            return self.retry_find_element(error.target, new_screen_state)
        
        # 策略3：使用备选描述
        alternative_targets = self.get_alternative_targets(error.target)
        for alt_target in alternative_targets:
            try:
                return self.element_locator.find_element(alt_target, new_screen_state)
            except ElementNotFoundError:
                continue
        
        # 策略4：报告错误
        return self.report_error(error, context)
```

---

## 六、框架方案选择

### 6.1 为什么选择 APP 形式？

**核心原因：**

1. **系统权限需求**
   - 屏幕捕获需要 `MediaProjection` API，需要应用权限
   - UI 访问和操作需要 `AccessibilityService`，必须作为应用安装
   - 这些系统级权限无法通过其他方式获得

2. **本地 AI 模型部署**
   - AI 模型需要在设备本地运行
   - APP 形式可以完整集成 OCR、UI 检测、LLM 等模型
   - 便于模型管理和更新

3. **用户体验**
   - 提供友好的用户界面（管理用例、查看报告）
   - 可以独立运行，不依赖 PC
   - 支持离线使用

4. **开发便利性**
   - Android SDK 提供完整的开发工具链
   - 调试和测试方便
   - 社区资源丰富

### 6.2 与其他方案对比

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **APP 形式** ⭐ | 系统权限完整、用户体验好、独立运行 | 需要安装 APP | **推荐：完全本地部署** |
| 系统服务 | 更轻量、后台运行 | 管理不便、需要系统级权限 | 企业级部署 |
| PC 端工具 | PC 端管理方便 | 必须连接 PC、AI 模型在 PC 端 | 不适合本地部署 |
| ADB 方式 | 无需安装应用 | 依赖 PC、无法本地部署 AI | 不适合本地部署 |

### 6.3 当前实现方案

**采用：标准 APP 形式（后续可优化为轻量级）**

**当前结构：**
- 标准 Android APP
- 使用 Jetpack Compose UI 框架
- 完整的用户界面
- 后续可优化为轻量级版本

**优化方向：**
- 简化用户界面（只保留必要功能）
- 主要功能在后台服务中运行
- 支持通知栏控制
- 可选：PC 端管理工具

---

## 七、部署架构

### 7.1 完全本地部署方案（优先方案）

**核心原则：所有 AI 模型部署在手机本地，完成完整的用例分析、执行、图像识别和结果输出。**

```
┌─────────────────────────────────────────────────────────┐
│                   测试设备（手机）                         │
│  ┌───────────────────────────────────────────────────┐ │
│  │            TestWings APP                          │ │
│  │  ┌──────────────┐  ┌──────────────┐             │ │
│  │  │  本地AI模型   │  │  设备控制     │             │ │
│  │  │              │  │              │             │ │
│  │  │ - OCR        │  │ - 屏幕捕获    │             │ │
│  │  │ - UI检测     │  │ - 操作执行    │             │ │
│  │  │ - LLM        │  │ - 结果验证    │             │ │
│  │  │ - Vision-LM  │  │              │             │ │
│  │  └──────────────┘  └──────────────┘             │ │
│  │  ┌──────────────┐  ┌──────────────┐             │ │
│  │  │  测试执行引擎  │  │  数据存储     │             │ │
│  │  │              │  │              │             │ │
│  │  │ - 用例理解    │  │ - SQLite     │             │ │
│  │  │ - 操作规划    │  │ - 结果存储    │             │ │
│  │  │ - 报告生成    │  │ - 截图缓存    │             │ │
│  │  └──────────────┘  └──────────────┘             │ │
│  └───────────────────────────────────────────────────┘ │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │
│  │  目标APP     │  │  系统服务   │  │  用户界面    │ │
│  │  (被测应用)  │  │  (Accessibility)│ │  (管理界面)  │ │
│  └──────────────┘  └──────────────┘  └──────────────┘ │
└─────────────────────────────────────────────────────────┘

所有功能完全本地执行，无需网络连接，降低测试环境复杂度
```

**优势：**
- ✅ 降低测试环境复杂度，无需搭建服务器
- ✅ 保护数据隐私，不上传敏感信息
- ✅ 离线可用，不依赖网络
- ✅ 响应速度快，无网络延迟

### 7.2 企业级混合部署方案（可选）

**适用场景：企业级大规模使用，需要集中管理和监控。**

```
┌─────────────────────────────────────────────────────────┐
│                     企业级 LLM 服务器                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │  用例理解    │  │  屏幕理解    │  │  操作规划    │  │
│  │  LLM        │  │  Vision-LM   │  │  LLM        │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
│  ┌──────────────┐  ┌──────────────┐                   │
│  │  Web服务     │  │  数据存储    │                   │
│  │  (FastAPI)   │  │  (PostgreSQL)│                   │
│  └──────────────┘  └──────────────┘                   │
└────────────────────┬────────────────────────────────────┘
                     │
                     │ HTTP/WebSocket
                     │
┌────────────────────▼────────────────────────────────────┐
│           多个 TestWings APP (手机端)                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │  本地模型    │  │  设备控制     │  │  系统服务   │  │
│  │              │  │              │  │              │  │
│  │ - OCR        │  │ - 屏幕捕获    │  │  (Accessibility)│
│  │ - UI检测     │  │ - 操作执行    │  │              │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
└─────────────────────────────────────────────────────────┘
```

**优势：**
- ✅ 集中管理，统一更新模型
- ✅ 支持大规模并发
- ✅ 降低单个设备内存压力

---

## 八、性能优化策略

### 7.1 识别性能优化

1. **增量识别**：只识别变化区域
2. **缓存机制**：缓存UI元素识别结果
3. **模型量化**：使用量化模型减少计算量
4. **并行处理**：屏幕识别和操作执行并行

### 7.2 网络优化

1. **本地模型优先**：优先使用本地模型，减少网络请求
2. **批量请求**：合并多个AI请求
3. **结果缓存**：缓存AI分析结果
4. **压缩传输**：压缩屏幕截图和传输数据

### 7.3 执行效率优化

1. **智能等待**：根据UI状态智能等待，而非固定延时
2. **操作合并**：合并连续操作，减少屏幕刷新
3. **失败快速恢复**：快速识别失败并重试

---

## 九、安全与隐私

### 8.1 数据安全

1. **加密传输**：所有数据传输使用HTTPS/WSS
2. **数据加密存储**：敏感数据加密存储
3. **访问控制**：基于角色的访问控制（RBAC）

### 8.2 隐私保护

1. **本地处理优先**：优先使用本地模型，减少数据上传
2. **数据脱敏**：上传前对敏感信息脱敏
3. **用户控制**：用户可控制数据上传范围
4. **数据保留策略**：自动清理过期数据

---

## 十、扩展性设计

### 9.1 插件系统

支持插件扩展功能：
- **自定义识别器**：支持自定义UI元素识别器
- **自定义操作**：支持自定义操作类型
- **自定义验证器**：支持自定义验证逻辑

### 9.2 多平台支持

- **Android**：完整支持
- **iOS**：基础支持（受系统限制）
- **Web**：通过浏览器自动化扩展支持

### 9.3 多语言支持

- **测试用例**：支持多语言测试用例
- **UI识别**：支持多语言UI识别
- **报告生成**：支持多语言报告

---

## 十一、开发路线图

### Phase 1: 核心功能（MVP）
- [ ] 基础屏幕识别（OCR + 简单UI检测）
- [ ] 基础操作执行（点击、输入）
- [ ] 简单用例执行
- [ ] 基础报告生成

### Phase 2: AI增强
- [ ] LLM集成（用例理解、屏幕理解）
- [ ] 智能元素定位
- [ ] 异常处理优化

### Phase 3: 完善功能
- [ ] 复杂操作支持（滑动、手势）
- [ ] 结果验证增强
- [ ] 报告完善

### Phase 4: 优化与扩展
- [ ] 性能优化
- [ ] 插件系统
- [ ] 多平台支持
- [ ] 企业级功能

