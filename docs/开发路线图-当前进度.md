# TestWings 开发路线图 - 当前进度

> 本文档记录 TestWings 项目的开发进度和下一步计划

## 🎯 终极目标

**TestWings 是一个基于 AI 的 APP 自动化测试框架，能够：**

1. **理解测试用例**：支持自然语言描述，AI 自动理解并生成测试计划
2. **智能屏幕识别**：结合 OCR、计算机视觉和 Accessibility Service，准确识别 UI 元素
3. **智能元素定位**：基于语义匹配，自动定位目标元素，适应 UI 变化
4. **自动化执行**：像人一样操作手机，执行点击、输入、滑动等操作
5. **智能结果验证**：自动验证测试结果，生成详细测试报告
6. **自适应学习**：从测试执行中学习，持续优化识别和执行准确率

**核心原理**：实时屏幕识别 + AI 推理决策 + 自动化操作执行

---

## ✅ 已完成功能

### Phase 0: 项目基础（已完成）
- [x] 项目结构搭建
- [x] Android 开发环境配置
- [x] 基础 UI 界面（Jetpack Compose）
- [x] **屏幕捕获功能** ⭐
  - [x] MediaProjection API 集成
  - [x] 前台服务实现（兼容 HarmonyOS）
  - [x] 截图保存到本地
  - [x] 权限管理
  - [x] MediaProjection 实例复用优化
  - [x] 授权弹窗延迟优化（从 3.5 秒优化到 0-500ms）

### Phase 1: 核心功能（MVP）- 进行中

#### 1.1 基础操作执行 ⭐ **已完成**
**目标**：实现能够操作手机的基础能力

**任务清单：**
- [x] 实现 AccessibilityService
  - [x] 创建 AccessibilityService 类
  - [x] 配置 AndroidManifest.xml
  - [x] 获取 UI 元素信息（文本、坐标、类型）
  - [x] 获取 Accessibility 树结构
- [x] 实现点击操作
  - [x] 根据坐标点击
  - [x] 根据元素信息点击
  - [x] 点击事件分发
- [x] 实现输入操作
  - [x] 文本输入
  - [x] 清空输入框
  - [x] 特殊字符处理（基础支持）
- [x] 实现滑动操作
  - [x] 上下滑动
  - [x] 左右滑动
  - [x] 自定义滑动路径
- [x] 实现系统按键
  - [x] 返回键
  - [x] 主页键
  - [x] 最近任务键
- [x] 测试基本操作流程
  - [x] 创建测试界面
  - [x] 验证点击功能 ✅
  - [x] 验证滑动功能 ✅
  - [x] 验证返回键功能 ✅
  - [x] 添加操作反馈和倒计时功能

**完成时间**：2025-01-08

**测试状态**：✅ 已测试通过
- ✅ 屏幕捕获功能正常
- ✅ 上下左右滑动操作正常
- ✅ 点击中心操作正常
- ✅ 返回键操作正常

---

## 🚀 下一步计划

### Phase 1: 核心功能（MVP）- 进行中

#### 1.2 OCR 文字识别 ⭐ **已完成**
**目标**：能够识别屏幕上的文字，为后续的智能元素定位和测试用例执行打下基础

**完成时间**：2025-12-09

**任务清单：**
- [x] 选择 OCR 库（使用 ML Kit Text Recognition）
- [x] 集成 OCR 库到项目
- [x] 实现截图 OCR 识别功能
- [x] 提取文字内容和位置信息
- [x] 显示识别结果（用于测试和调试）
- [x] 优化识别性能（异步处理）
- [x] 实现自动检测和选择机制（HarmonyOS/Android 自动适配）

**技术选型**：
- **ML Kit Text Recognition**（已采用）
  - ✅ 轻量级、易集成、免费、支持中文
  - ✅ 已验证在 HarmonyOS 4.2 上可用（即使没有 Google Play Services）
  - ✅ 识别准确率良好，性能优秀

**重要发现**：
- ✅ ML Kit Text Recognition 在 HarmonyOS 4.2 上可以正常工作
- ✅ 即使没有完整的 Google Play Services，ML Kit 的 Text Recognition 功能仍然可用
- ✅ 识别功能正常，能够准确识别屏幕文字并提取位置信息

**测试状态**：✅ 已测试通过（基础功能）
- ✅ OCR识别功能正常
- ✅ 能够识别屏幕上的文字
- ✅ 能够提取文本块的位置信息（坐标）
- ✅ 界面显示识别结果完整（文本块详情）

**已知问题**：⚠️ OCR识别准确性有待提升
- ✅ 黑底白字场景：识别准确
- ⚠️ 灰底蓝字场景：识别不准确
  - 问题示例："捕获屏幕" 识别成 "鋪获屏幕" 或 "埔获屏幕"
  - 原因分析：ML Kit 对某些颜色组合（灰底蓝字）的识别能力有限
  - 影响范围：影响测试用例执行中的文本定位和验证

---

#### 1.3 简单测试用例执行
**目标**：能够执行一个简单的测试用例

**任务清单：**
- [ ] 设计简单的测试用例格式（JSON）
- [ ] 解析测试用例
- [ ] 执行测试步骤（结合操作执行和 OCR）
- [ ] 记录执行结果
- [ ] 生成简单报告

**预计时间**：5-7 天

---

#### 1.4 基础报告生成
**目标**：生成测试执行报告

**任务清单：**
- [ ] 设计报告格式
- [ ] 收集执行数据
- [ ] 生成 HTML/JSON 报告
- [ ] 包含截图和日志

**预计时间**：3-5 天

---

## 📋 后续阶段（Phase 2-4）

### Phase 2: AI 增强
- [ ] UI 元素检测（YOLOv8）
- [ ] 本地 LLM 集成（Qwen-1.8B）
- [ ] 用例理解功能
- [ ] 智能元素定位
- [ ] 操作规划

### Phase 3: 完善功能
- [ ] 复杂操作支持（手势、长按等）
- [ ] 结果验证增强
- [ ] 异常处理优化
- [ ] 报告完善

### Phase 4: 优化与扩展
- [ ] 性能优化
- [ ] 插件系统
- [ ] 多平台支持
- [ ] 企业级功能

---

## 🎯 当前里程碑

**当前阶段**：Phase 1 - 核心功能（MVP）

**当前任务**：优化 OCR 识别准确性

**完成度**：约 75%
- ✅ 屏幕捕获（100%）
- ✅ 基础操作执行（100%）
  - ✅ 点击操作（坐标点击、元素点击）
  - ✅ 滑动操作（上下左右、自定义路径）
  - ✅ 输入操作（文本输入、清空）
  - ✅ 系统按键（返回、主页、最近任务）
- ✅ OCR 识别（85%）⭐ 基础功能已完成，准确性待优化
  - ✅ ML Kit Text Recognition 集成
  - ✅ 自动检测和选择机制（HarmonyOS/Android 适配）
  - ✅ OCR结果显示界面
  - ✅ 文本块位置信息提取
  - ⚠️ 识别准确性优化（灰底蓝字场景识别不准确）
- ✅ 用例执行（100%）⭐ 已完成
  - ✅ 测试用例格式设计（JSON）
  - ✅ 测试用例解析和执行
  - ✅ 截图和OCR集成
  - ✅ 验证功能
- ⏳ OCR准确性优化（0%）⭐ 下一步
- ⏳ 报告生成（0%）

---

## 📝 开发原则

1. **先做能用的，再做完美的**
   - MVP 版本优先实现核心功能
   - 后续逐步优化和完善

2. **循序渐进**
   - 每个功能独立实现和测试
   - 确保每个功能稳定后再继续

3. **本地优先**
   - 优先使用本地模型和本地处理
   - 降低环境复杂度

4. **文档同步**
   - 代码和文档同步更新
   - 记录开发过程中的问题和解决方案

---

## 🔄 更新记录

- **2025-01-08**：完成屏幕捕获功能，开始规划下一步
- **2025-01-08**：创建开发路线图文档
- **2025-01-08**：完成基础操作执行功能
  - ✅ 实现 AccessibilityService
  - ✅ 实现点击、滑动、输入、系统按键等操作
  - ✅ 创建操作测试界面和反馈机制
  - ✅ 所有基础操作测试通过
- **2025-01-08**：更新进度，确定下一步为 OCR 文字识别
- **2025-01-08**：优化屏幕捕获授权弹窗延迟
  - ✅ 优化授权弹窗显示延迟（从 3.5 秒优化到 0-500ms）
  - ✅ 添加智能服务状态检查（服务已运行时立即显示弹窗）
  - ✅ 减少固定延迟时间（前台服务启动通常很快）
  - ✅ 优化授权后捕获延迟（从 1.5 秒优化到 500ms）
- **2025-12-09**：完成 OCR 文字识别功能
  - ✅ 集成 ML Kit Text Recognition
  - ✅ 实现 OCR 识别功能（截图后自动识别）
  - ✅ 创建 OCR 结果显示界面（文本块详情、位置信息）
  - ✅ 实现自动检测和选择机制（HarmonyOS/Android 自动适配）
  - ✅ 验证 ML Kit 在 HarmonyOS 4.2 上可用（即使没有 Google Play Services）
  - ✅ 创建 OCR 功能验证报告文档
- **2025-01-11**：完成简单测试用例执行功能
  - ✅ 设计测试用例格式（JSON）
  - ✅ 实现测试用例解析器
  - ✅ 实现测试执行引擎（TestExecutor）
  - ✅ 实现元素定位器（ElementLocator）
  - ✅ 集成截图和OCR到测试执行流程
  - ✅ 修复截图重复问题（一次截图操作只产生一张截图）
  - ✅ 创建测试用例管理界面
- **2025-01-11**：发现 OCR 识别准确性问题
  - ⚠️ 灰底蓝字场景识别不准确（如"捕获屏幕"识别成"鋪获屏幕"或"埔获屏幕"）
  - 📋 制定优化方案：图像预处理增强、后处理纠错、多引擎融合

---

**下一步行动**：优化 OCR 识别准确性，重点解决灰底蓝字场景识别不准确的问题。优先实施方案一（图像预处理增强），预计提升准确率 20-30%。

